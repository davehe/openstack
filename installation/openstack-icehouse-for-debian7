

openstack 手动安装手册


部署架构
采用多节点分开部署vlan方式


物理机

ip:eth0:10.1.99.101
Name: controller
vCPU: 8
Memory :16G
Disk:300G



ip:eth0:10.1.99.102  eth1:无ip与交换机对应端口绑trunk     
Name: network
vCPU: 8
Memory :16G
Disk:300G


ip:eth0:10.1.99.104  eth1:无ip与交换机对应端口绑trunk     
Name: compute1
vCPU: 8
Memory :16G
Disk:1T

ip:eth0:10.1.99.106  eth1:无ip与交换机对应端口绑trunk     
Name: compute2
vCPU: 8
Memory :48G
Disk:300G



ip:eth0:10.1.99.105  
Name: cinder
vCPU: 8
Memory :16G
Disk:300G



网络设置

controller
     eth0:10.1.99.101   (management network)
     eht1:(disabled)

network
     eth0:10.1.99.102   (management network)
     eht1:no ip  (private network)

compute1
     eth0:10.1.99.104   (management network)
     eht1:no ip  (private network)

compute2
     eth0:10.1.99.106   (management network)
     eht2:no ip  (private network)
     
cinder
     eth0:10.1.99.105   (management network)
     eht1:(disabled)


network,compute1,compute2 eth1配置
auto eth1
iface eth1 inet manual
    up ip link set dev $IFACE up
    down up link set dev $IFACE down


公共配置

内部已经搭好一套oenpstack源,每台节点上配置/etc/apt/sources.list
deb http://10.1.1.172/debian  wheezy main non-free contrib
deb http://10.1.1.172/openstack_icehouse icehouse main
deb http://10.1.1.172/openstack_icehouse icehouse-backports main

更新并安装key
apt-get update && apt-get install gplhost-archive-keyring

更新升级最新操作系统
apt-get update && apt-get dist-upgrade
reboot

更改hosts配置
10.1.99.101 controller 
10.1.99.102 network
10.1.99.104 compute1
10.1.99.106 compute2
10.1.99.105 cinder


安装ntp服务
apt-get install ntpdate
更改配置文件/etc/default/ntpdate  指定到内网时间服务器10.1.1.10
NTPSERVERS="10.1.1.10"


增加定时任务
*/30 * * * *    /usr/sbin/ntpdate-debian && /sbin/hwclock --directisa -w 


安装python-mysqldb 
apt-get install python-mysqldb






控制节点(contronller 10.1.99.101) 安装

安装数据库mysql

apt-get install mysql-server

更改配置文件/etc/mysql/my.cnf
[mysqld]
...
bind-address = 10.0.0.11
[mysqld]
...
default-storage-engine = innodb
innodb_file_per_table
collation-server = utf8_general_ci
init-connect = 'SET NAMES utf8'

重启数据库
service mysql restart

删除匿名用户,加强数据库安全性
mysql_install_db
mysql_secure_installation


安装消息服务
apt-get install rabbitmq-server

更改密码
rabbitmqctl change_password guest hc1226

配置/etc/rabbitmq/rabbitmq-env.conf 
RABBITMQ_NODE_IP_ADDRESS=10.1.99.101

重启服务
/etc/init.d/rabbitmq-server restart

安装keystone服务
apt-get install keystone #会初始化keystone数据库,会为keystone设置admin账户的token

更改keystone用户权限
GRANT ALL PRIVILEGES ON `keystonedb`.* TO 'keystone'@% IDENTIFIED BY 'hc';
GRANT ALL PRIVILEGES ON `keystonedb`.* TO 'keystone'@'%' IDENTIFIED BY 'hc';


设置认证信息
export OS_SERVICE_TOKEN=hc
export OS_SERVICE_ENDPOINT=http://controller:35357/v2.0

创建管理员和系统服务使用的租户
keystone tenant-create --name=admin --description="Admin Tenant"
keystone tenant-create --name=service --description="Service Tenant"

创建管理员用户
keystone user-create --name=admin --pass=admin --email=admin@example.com

创建管理员角色
keystone role-create --name=admin

为管理员用户分配管理员角色
keystone user-role-add --user=admin --tenant=admin --role=admin

为keystone服务建立service
keystone service-create --name=keystone --type=identity --description="Keystone Identity Service"

为keystone建立service和endpoint关联
keystone endpoint-create \
--service-id=$(keystone service-list | awk '/ identity / {print $2}') \
--publicurl=http://controller:5000/v2.0 \
--internalurl=http://controller:5000/v2.0 \
--adminurl=http://controller:35357/v2.0


验证keystone安装的正确性
取消先前的Token变量，不然会干扰新建用户的验证。
unset OS_SERVICE_TOKEN OS_SERVICE_ENDPOINT


用命令行方式验证
keystone --os-username=admin --os-password=admin --os-auth-url=http://controller:35357/v2.0 token-get
keystone --os-username=admin --os-password=admin --os-tenant-name=admin --os-auth-url=http://controller:35357/v2.0 token-get


写入环境变量配置
export OS_USERNAME=admin
export OS_PASSWORD=admin
export OS_TENANT_NAME=admin
export OS_AUTH_URL=http://controller:35357/v2.0


加载环境变量
source admin-openrc.sh

测试
keystone token-get




安装glance服务

apt-get install glance python-glanceclient #初始化glance数据库


配置glance连接数据库/etc/glance/glance-api.conf and /etc/glance/glanceregistry.conf

[database]
connection = mysql://glance-common:hc1226@controller/glancedb


配置数据库权限
GRANT ALL PRIVILEGES ON `glancedb`.* TO 'glance-common'@'localhost' IDENTIFIED BY 'hc';
GRANT ALL PRIVILEGES ON `glancedb`.* TO 'glance-common'@'%' IDENTIFIED BY 'hc';


创建glance 用户
keystone user-create --name=glance --pass=hc --email=glance@example.com

并分配service角色
keystone user-role-add --user=glance --tenant=service --role=admin

创建glance 服务
keystone service-create --name=glance --type=image --description="Glance Image Service"

创建keystone 的endpoint
keystone endpoint-create \
--service-id=$(keystone service-list | awk '/ image / {print $2}')  \
--publicurl=http://controller:9292 \
--internalurl=http://controller:9292 \
--adminurl=http://controller:9292


修改/etc/glance/glance-api.conf and /etc/glance/glanceregistry.conf
[keystone_authtoken]
auth_host = 10.1.99.101
auth_port = 35357
auth_protocol = http
admin_tenant_name = service
admin_user = glance
admin_password = hc

启动glance服务
/etc/init.d/glance-api start
/etc/init.d/glance-registry start


测试
root@controller:glance# glance image-list
+----+------+-------------+------------------+------+--------+
| ID | Name | Disk Format | Container Format | Size | Status |
+----+------+-------------+------------------+------+--------+
+----+------+-------------+------------------+------+--------+


nova安装与配置

apt-get install nova-api nova-cert nova-conductor nova-consoleauth nova-novncproxy nova-scheduler python-novaclient

在keystone中创建nova相应的用户和服务

keystone user-create --name=nova --pass=hc --email=nova@example.com
keystone user-role-add --user=nova --tenant=service --role=admin

keystone 注册服务
keystone service-create --name=nova --type=compute --description="Nova Compute Service"

keystone 注册endpoint
keystone endpoint-create \
--service-id=$(keystone service-list | awk '/ compute / {print $2}')  \
--publicurl=http://controller0:8774/v2/%\(tenant_id\)s \
--internalurl=http://controller0:8774/v2/%\(tenant_id\)s \
--adminurl=http://controller0:8774/v2/%\(tenant_id\)s


设置数据库权限
GRANT ALL PRIVILEGES ON `novadb`.* TO 'nova-common'@'localhost' IDENTIFIED BY 'hc';
GRANT ALL PRIVILEGES ON `novadb`.* TO 'nova-common'@'%' IDENTIFIED BY 'hc'; 


配置nova连接数据库
[database]
connection = mysql://nova-common:hc@controller/novadb

my_ip = 10.1.99.101
vncserver_proxyclient_address=10.1.99.101
vncserver_listen=10.1.99.101

rabbit_host = 10.1.99.101
rabbit_userid = guest
rabbit_password = hc

[keystone_authtoken]
auth_host = 10.1.99.101
auth_port = 35357
auth_protocol = http
admin_tenant_name = service
admin_user = nova
admin_password = hc
auth_version = v2.0


启动服务

service openstack-nova-api start
service openstack-nova-cert start
service openstack-nova-consoleauth start
service openstack-nova-scheduler start
service openstack-nova-conductor start
service openstack-nova-novncproxy start

检查服务

nova-manage service list
Binary           Host                                 Zone             Status     State Updated_At
nova-conductor   controller                           internal         enabled    :-)   2014-11-05 07:59:42
nova-consoleauth controller                           internal         enabled    :-)   2014-11-05 07:59:36
nova-cert        controller                           internal         enabled    :-)   2014-11-05 07:59:33
nova-scheduler   controller                           internal         enabled    :-)   2014-11-05 07:59:39



Neutron server安装与配置

apt-get install neutron-server

在keystone中创建 Neutron 相应的用户和服务
keystone user-create --name neutron --pass hc --email neutron@example.com
keystone user-role-add --user neutron --tenant service --role admin
keystone service-create --name neutron --type network --description "OpenStack Networking"
keystone endpoint-create \
--service-id $(keystone service-list | awk '/ network / {print $2}') \
--publicurl http://controller:9696 \
--adminurl http://controller:9696 \
--internalurl http://controller:9696
  

配置数据库权限
GRANT ALL PRIVILEGES ON `neutrondb`.* TO 'neutron-common'@'localhost'  IDENTIFIED BY 'hc';
GRANT ALL PRIVILEGES ON `neutrondb`.* TO 'neutron-common'@'%'  IDENTIFIED BY 'hc';


配置/etc/neutron.conf
rabbit_host = 10.1.99.101
rabbit_userid = guest
rabbit_password = hc

[database]
connection = mysql://neutron-common:hc@neutron/neutrondb

auth_strategy keystone
[keystone_authtoken]
auth_host = 10.1.99.101
auth_port = 35357
auth_protocol = http
admin_tenant_name = service
admin_user = neutron
admin_password = hc

# ======== neutron nova interactions ==========
notify_nova_on_port_status_changes = True
notify_nova_on_port_data_changes = True
nova_url = http://10.1.99.101:8774/v2
nova_admin_username = admin
nova_admin_tenant_id = a5e40cc19c7d4022a0a32dd67588c8bb
nova_admin_password = ta0mee@123
nova_admin_auth_url = http://10.1.99.101:35357/v2.0


配置Neutron openvswitch 使用vlan模式 /etc/neutron/plugins/openvswitch
[ovs]
tenant_network_type = vlan
network_vlan_ranges = physnet_inner:10:20   #稍后会在交换机设置trunk号范围
enable_tunneling = False
integration_bridge = br-int  #默认虚拟机虚拟子网网桥
local_ip = 10.1.99.101
bridge_mappings = physnet_inner:br-inner #br-inner稍后会在网络节点和计算节点创建 并将网卡eth1桥接上去
[agent]
[securitygroup]


配置/etc/nova/nova.conf 使用Neutron 作为network服务
neutron_url=http://10.1.99.101:9696
neutron_auth_strategy=keystone
neutron_admin_tenant_name=service
neutron_admin_username=neutron
neutron_admin_password=hc
neutron_admin_auth_url=http://10.1.99.101:35357/v2.0


重启nova controller 上的服务

service nova-api restart
service nova-scheduler restart
service nova-conductor restart

启动Neutron server
service neutron-server start





网络节点安装 (network 10.1.99.102):

允许ip forward
vi /etc/sysctl.conf 
net.ipv4.ip_forward=1
net.ipv4.conf.all.rp_filter=0
net.ipv4.conf.default.rp_filter=0

立即生效
sysctl -p
apt-get install linux-headers-3.2.0-4-amd64  bridge-utils
apt-get install neutron-plugin-ml2 neutron-plugin-openvswitch-agent openvswitch-datapath-dkms neutron-l3-agent neutron-dhcp-agent


配置/etc/neutron.conf  (可以cp一份从控制节点)
rabbit_host = 10.1.99.101
rabbit_userid = guest
rabbit_password = hc

[database]
connection = mysql://neutron-common:hc@controller/neutrondb

auth_strategy keystone
[keystone_authtoken]
auth_host = 10.1.99.101
auth_port = 35357
auth_protocol = http
admin_tenant_name = service
admin_user = neutron
admin_password = hc

# ======== neutron nova interactions ==========
notify_nova_on_port_status_changes = True
notify_nova_on_port_data_changes = True
nova_url = http://10.1.99.101:8774/v2
nova_admin_username = admin
nova_admin_tenant_id = a5e40cc19c7d4022a0a32dd67588c8bb
nova_admin_password = ta0mee@123
nova_admin_auth_url = http://10.1.99.101:35357/v2.0


创建br-inner网桥,将eth1桥接上去,用以网络节点与计算节点互联
/etc/init.d/openvswitch-switch start
ovs-vsctl add-br br-inner
ovs-vsctl add-port br-inner eth1
ovs-vsctl show
a219b33a-9f74-42f3-bd33-8f983f2ad74f
    Bridge br-int
        fail_mode: secure
        Port br-int
            Interface br-int
                type: internal
    Bridge br-inner
        Port br-inner
            Interface br-inner
                type: internal
        Port "eth1"
            Interface "eth1"
    ovs_version: "2.3.0"




设置ovs-agent服务配置  使用vlan模式 /etc/neutron/plugins/openvswitch
[ovs]
tenant_network_type = vlan
network_vlan_ranges = physnet_inner:10:20   #稍后会在交换机设置trunk号范围
enable_tunneling = False
integration_bridge = br-int  #默认虚拟机虚拟子网网桥
local_ip = 10.1.99.102
bridge_mappings = physnet_inner:br-inner #br-inner稍后会在网络节点和计算节点创建 并将网卡eth1桥接上去
[agent]
[securitygroup]


设置dhcp-agent服务配置  /etc/neutron/dhcp_agent.ini 在此模式下,网络节点之提供DHCP与元数据转发服务,不需要启动L3服务 /etc/neutron/dhcp_agent.ini
[DEFAULT]
debug = True 
interface_driver = neutron.agent.linux.interface.OVSInterfaceDriver
dhcp_driver = neutron.agent.linux.dhcp.Dnsmasq
enable_metadata_network = True

如果有安装元数据代理neutron-metadata-agent,则要确保元数据指向nova metadata server 10.1.99.101,即nova-api服务控制网络的ip地址
/etc/neutron/metadata_agent.ini
...
nova_metadata_ip = 10.1.99.101
metadata_proxy_shared_secret = hc
相应的要在控制节点10.1.99.101 更改/etc/nova/nova.conf
service_neutron_metadata_proxy=True
neutron_metadata_proxy_shared_secret=hc


启动Neutron 服务

service neutron-plugin-openvswitch-agent start
service neutron-dhcp-agent start

service neutron-l3-agent start #这种模式在此环境没有使用
service neutron-metadata-agent start #如果安装使用元数据代理可以启动起来,这里没有使用





计算节点安装(compute1 10.1.99.104)：

安装包
apt-get install nova-compute-kvm

配置/etc/nova/nova.conf
[DEFAULT]
auth_strategy=keystone

rabbit_host = 10.1.99.101
rabbit_userid = guest
rabbit_password = hc1226

glance_host=10.1.99.101
glance_port=9292
glance_protocol=http
glance_api_servers=10.1.99.101:9292
glance_num_retries=0


neutron_url=http://10.1.99.101:9696
neutron_auth_strategy=keystone
neutron_admin_tenant_name=service
neutron_admin_username=neutron
neutron_admin_password=hc1226
neutron_admin_auth_url=http://10.1.99.101:35357/v2.0
service_neutron_metadata_proxy=True

[database]
connection = mysql://nova-common:hc1226@controller/novadb

[spice]
html5proxy_base_url=http://10.1.99.101:6082/spice_auto.html
server_listen=0.0.0.0
server_proxyclient_address=10.1.99.104  #计算节点ip
enabled=true

[keystone_authtoken]
auth_host = 10.1.99.101
auth_port = 35357
auth_protocol = http
admin_tenant_name = service
admin_user = nova
admin_password = hc1226
auth_version = v2.0


配置内核参数
net.ipv4.conf.all.rp_filter=0
net.ipv4.conf.default.rp_filter=0

sysctl -p











